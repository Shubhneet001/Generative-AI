{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7824d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85cedac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35262685",
   "metadata": {},
   "source": [
    "# 1. Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b1bb37",
   "metadata": {},
   "source": [
    "- Document Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd10d8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've been working on AI safety for two decades at least. >> Yeah, I was convinced we can make safe AI, but the more I looked at it, the more I realized it's not something we can actually do. >> You have made a series of predictions about a variety of different states. So, what is your prediction for 2027? [Music] >> Dr. Roman Yimpolski is a globally recognized voice on AI safety and associate professor of computer science. He educates people on the terrifying truth of AI >> and what we need to\n"
     ]
    }
   ],
   "source": [
    "# video_id = \"Vj2Q_11tol0\"\n",
    "video_id = \"UclrVWafRAI\"\n",
    "\n",
    "try:\n",
    "    # Try to fetch English transcript\n",
    "    transcript_snippets = YouTubeTranscriptApi().fetch(video_id, languages=[\"en\"])\n",
    "\n",
    "    # Flatten into plain text\n",
    "    transcript = \" \".join(snippet.text for snippet in transcript_snippets)\n",
    "    print(transcript[:500])\n",
    "\n",
    "except TranscriptsDisabled:\n",
    "    print(\"No captions available for this video.\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f56327cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FetchedTranscriptSnippet(text=\"You've been working on AI safety for two\", start=0.16, duration=2.56)\n"
     ]
    }
   ],
   "source": [
    "print(transcript_snippets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d9608d",
   "metadata": {},
   "source": [
    "- Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.create_documents([transcript])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2f03df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content=\"You've been working on AI safety for two decades at least. >> Yeah, I was convinced we can make safe AI, but the more I looked at it, the more I realized it's not something we can actually do. >> You have made a series of predictions about a variety of different states. So, what is your prediction for 2027? [Music] >> Dr. Roman Yimpolski is a globally recognized voice on AI safety and associate professor of computer science. He educates people on the terrifying truth of AI >> and what we need to do to save humanity. >> In 2 years, the capability to replace most humans in most occupations will come very quickly. I mean, in 5 years, we're looking at a world where we have levels of unemployment we never seen before. Not talking about 10% but 99%. And that's without super intelligence. A system smarter than all humans in all domains. So, it would be better than us at making new AI. But it's worse than that. We don't know how to make them safe and yet we still have the smartest people in\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1103c24",
   "metadata": {},
   "source": [
    "- Embedding Generation & Storing in Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4ee70b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_10668\\611035559.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "d:\\anaconda3\\envs\\genai_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59d95bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '96419f9a-0375-448b-ac11-326a8505ee3e',\n",
       " 1: '0300c138-fa27-4f83-9ec6-64e505d04a3d',\n",
       " 2: 'f5b83793-a3e8-48d7-8e47-38f03bee6ddc',\n",
       " 3: '210a9989-43e7-4480-b2d1-8d82f0b6df34',\n",
       " 4: '35c0474e-2223-4796-96ed-a3a28ec704bb',\n",
       " 5: '52d050bb-286b-4852-a3b1-4c13d5b8d408',\n",
       " 6: '065f6207-e804-4578-99d4-b18f39cf1aa6',\n",
       " 7: '3cc8cf33-473c-4a8f-8be6-8b9133236e4b',\n",
       " 8: '02508239-2d11-41ae-aa8a-061cf8cb7184',\n",
       " 9: '0a406d5e-df92-4e1d-87b4-7318b306b920',\n",
       " 10: 'a66469c3-1c34-4de6-9a24-44b040688223',\n",
       " 11: '6e47418a-61ba-475c-864b-caa1771c9003',\n",
       " 12: 'a7a8c9c9-45c2-435d-9c2e-118b2b74ac99',\n",
       " 13: 'bf1a195b-c4a1-4d63-8442-d6096ab7728e',\n",
       " 14: '37e4dab8-0432-4e80-b1cb-9ddda1fe289e',\n",
       " 15: 'd20fecf6-a619-4965-843e-696e87b26c28',\n",
       " 16: 'eb73ecc7-5ce9-4f96-a9df-a416385c014a',\n",
       " 17: '703eddef-09d7-413a-9d2e-8410921cec19',\n",
       " 18: '27431a60-5f24-47bd-9011-c9509e1f6ffd',\n",
       " 19: '0cf030e7-165e-4233-b212-4fddf0bbc1f1',\n",
       " 20: '4bd8dd35-b3d5-4115-a6b2-7e55a9a9a15a',\n",
       " 21: 'aaf20a67-4894-4405-9d4c-f445457fb035',\n",
       " 22: '915b1eba-be77-47b8-a913-68e0a2696078',\n",
       " 23: 'e37d09be-4d57-42fe-80e1-617773f2a5cb',\n",
       " 24: '4ae37ed9-cd34-4802-95df-ace9c9764c3b',\n",
       " 25: '9d85dd09-44ec-4b62-9001-cc4612d0b6d5',\n",
       " 26: '943f560d-dbc7-4268-9c63-caeba54478a5',\n",
       " 27: 'efc88989-55c5-4738-a415-2a1821dd451a',\n",
       " 28: 'add84cd9-9af7-46a2-bdea-2152588e0a5b',\n",
       " 29: '2b943559-9279-4779-899b-4a172440b308',\n",
       " 30: '3b3766e7-314d-4b36-b3b7-c3027bab636a',\n",
       " 31: 'c3a0cbc1-3b34-484e-843b-44104a037b04',\n",
       " 32: '65b93200-5fb3-41e2-b32d-e411fdd281d0',\n",
       " 33: 'ca07c263-d8f2-4bd5-a2bf-59037f6ffd23',\n",
       " 34: 'e69eea68-5785-4d62-8a09-dc25968b1c97',\n",
       " 35: '0b2ccb18-807e-41d4-91ce-0a9c57a7b871',\n",
       " 36: '47c95c0d-3b5c-47a5-9248-6a2a54b02f48',\n",
       " 37: '11399555-fdd3-419c-8c51-3744591812ba',\n",
       " 38: 'c17981bb-0bc8-4bed-86e8-9783bfe51298',\n",
       " 39: 'de4dff0e-a896-423c-8d01-ee5769c7c917',\n",
       " 40: '4dd24479-db98-4e06-af06-af0f3a1ac96a',\n",
       " 41: 'fce5b32d-414e-4d37-90bd-fbc50fbafae5',\n",
       " 42: 'c8bb8b75-d462-45e7-a3b3-9e399b3e1b1c',\n",
       " 43: 'cae0183a-3c6f-461c-86e5-dfc43604ffdb',\n",
       " 44: 'a37e2ae8-d677-45fa-8b4f-8a3c267b68d6',\n",
       " 45: 'bce1a5bf-5d1c-4b1a-b5bb-d76034882daf',\n",
       " 46: '4455b1b5-c270-4da0-b599-935c5b143466',\n",
       " 47: 'a7818224-fd9c-49e1-b7ee-0027cd29dfb2',\n",
       " 48: '4910821d-fbdd-41af-b2b9-21cc3fabf9aa',\n",
       " 49: '30342468-cc33-40f6-b3bc-fd2cb896854f',\n",
       " 50: '708ba7b7-ef31-426d-86ae-bc01c03c6565',\n",
       " 51: 'd2fae1c2-0967-49d9-a37e-73a715fdf88a',\n",
       " 52: '43e41b4e-8279-4491-9d5f-b59443913e54',\n",
       " 53: 'ab17edb7-6994-4e27-9ec1-54b5b7d2fe7c',\n",
       " 54: '0c525f0e-48b7-42fd-9e00-1a92d7609f57',\n",
       " 55: '7ae55c40-9a1d-400c-a5ea-411b9c11cc24',\n",
       " 56: 'a7e4f5c8-27cc-4708-bd54-27b0b7e9bf6a',\n",
       " 57: '8b334b08-d07b-47da-a444-c68dab7c8198',\n",
       " 58: '62466e1e-f354-41af-bc54-4e5749484baf',\n",
       " 59: '1f2c2553-b76a-4384-9ccc-a01cb3e31b3b',\n",
       " 60: 'f2245b89-812e-4634-b893-ae579069408e',\n",
       " 61: '0b33bd57-04ae-4477-83cd-37debbd77c24',\n",
       " 62: 'aeec8950-7845-4f32-b160-6bca7ff31850',\n",
       " 63: '42259871-58f0-4363-848d-c382cdd04463',\n",
       " 64: '87d4b7d0-10aa-4d35-805b-d34feadaa847',\n",
       " 65: 'f4d74c01-c24c-4298-a033-d2b9eb38cc0d',\n",
       " 66: 'c1f0e5bb-f561-4a84-a875-d1f7f6359cb1',\n",
       " 67: '123d30ce-1a02-48b8-aad6-0199cad5290f',\n",
       " 68: 'f920ae45-efa0-46f7-9952-43056e0f2698',\n",
       " 69: 'dd70ee2f-bfee-4fe9-b39d-898c9a621b87',\n",
       " 70: '6c1d827b-9301-415d-9f2c-a459f20d6878',\n",
       " 71: '65daad82-78b2-45ab-848a-b045f06a3332',\n",
       " 72: 'e2782946-6072-403e-adf2-fe11eb4503ae',\n",
       " 73: '56292fa3-e657-4e3c-802b-bf3ea9c11bb5',\n",
       " 74: 'a305afa8-4aaa-4b02-a6e3-f7104c844707',\n",
       " 75: '7680fffe-3d92-443f-ac6e-672973c72b28',\n",
       " 76: '69324d24-1cdd-466c-b032-d5771cc66aed',\n",
       " 77: '594a99a7-44db-4dae-8c89-811b93c90473',\n",
       " 78: '4cc04ff6-1a12-49f2-904c-9af0bfee279c',\n",
       " 79: '0bfbde71-ca55-4d64-8e7b-73d00a3c9671',\n",
       " 80: 'b8c2990f-abb5-4750-954d-01df151a5c6c',\n",
       " 81: 'd25ef471-8b90-4d64-83fb-d580e804918c',\n",
       " 82: 'c94a98e3-c5fd-4c7b-9a24-bd2d79973afb',\n",
       " 83: '25ac3c2c-c456-4da6-a825-bace2a771095',\n",
       " 84: '84a2be70-6c2b-42bc-b084-e24adae8c4d7',\n",
       " 85: '663521d5-3371-4ef3-998e-b99f61156197',\n",
       " 86: 'bda9de03-7e54-4fcc-b735-db2f4fbcd05b',\n",
       " 87: 'c92c6f52-a2ef-49c7-b4da-f9b521e6eda7',\n",
       " 88: '28e7ed8f-cad4-47d4-96e8-e006ad4db6d5',\n",
       " 89: '20dd568f-c387-4118-a5b7-2e4d3a523c89',\n",
       " 90: 'a2e55f5b-3e3b-4ef6-9cae-67161119fa8e',\n",
       " 91: '7a1cc1f5-d139-4a19-b71b-c15aeabf1086',\n",
       " 92: '31d730c2-4cbc-437d-bdf5-aff5b765d69f',\n",
       " 93: 'e4d0b4a8-5e3c-4402-af58-e5b4fffc069f',\n",
       " 94: '5c253724-eec8-45c9-b0fa-49f1a7d8ca81',\n",
       " 95: '903bac96-1e20-4e47-8c11-a39d8920a9fd',\n",
       " 96: '10c622e6-f9ed-439d-87ea-357b257711de',\n",
       " 97: 'e6b16c5c-9795-402d-b61d-81a823b40ac4',\n",
       " 98: '67ab64f2-ed8c-4cf1-985c-5a8175714fe9',\n",
       " 99: 'c954041d-2cc8-406f-9f32-cccbdb3f22f5',\n",
       " 100: 'db722382-3757-4773-9e45-66f5b487496c',\n",
       " 101: 'df636484-0efc-4ac0-b15a-39f0ec5616db',\n",
       " 102: '6529895e-0b9d-4a47-b32b-95b8b57b623f',\n",
       " 103: '563549d4-35ff-4154-8218-cfdbae30bd87',\n",
       " 104: 'd267b82a-62b4-4736-b9ed-34ff0d3916ea',\n",
       " 105: '311ef5c3-7d76-4660-921d-83721cd99183'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b471c3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='311ef5c3-7d76-4660-921d-83721cd99183', metadata={}, page_content=\"the fact that we are all one that there's a a divine creator and maybe also they all seem to consequence beyond this life. So maybe I should be thinking more about how I behave in this life and and where I might end up thereafter. Roman, thank you. >> Amen. [Music] [Music]\")]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.get_by_ids(['311ef5c3-7d76-4660-921d-83721cd99183'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98336ce4",
   "metadata": {},
   "source": [
    "# 2. Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910fb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002E23223DBB0>, search_kwargs={'k': 4})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='02508239-2d11-41ae-aa8a-061cf8cb7184', metadata={}, page_content=\"You go in and you find 10 more problems and then 100 more problems. And all of them are not just difficult. They're impossible to solve. There is no seinal work in this field where like we solved this, we don't have to worry about this. There are patches. There are little fixes we put in place and quickly people find ways to work around them. They drill break whatever safety mechanisms we have. So while progress in AI capabilities is exponential or maybe even hyper exponential, progress in AI safety is linear or constant. The gap is increasing. >> The gap between the >> how capable the systems are and how well we can control them, predict what they're going to do, explain their decision making. >> I think this is quite an important point because you said that we're basically patching over the issues that we find. So, we're developing this this core intelligence and then to stop it doing things or to stop it showing some of its unpredictability or its threats, the companies that are\"),\n",
       " Document(id='3cc8cf33-473c-4a8f-8be6-8b9133236e4b', metadata={}, page_content=\"better and better. And if you just project this forward enough, they're going to get better than us, smarter, more capable. And it happened. They are playing poker way better than average players. But more generally, it will happen with all other domains, all the other cyber resources. I wanted to make sure AI is a technology which is beneficial for everyone. So I started to work on making AI safer. >> Was there a particular moment in your career where you thought oh my god? >> First 5 years at least I was working on solving this problem. I was convinced we can make this happen. We can make safe AI and that was the goal. But the more I looked at it, the more I realized every single component of that equation is not something we can actually do. And the more you zoom in, it's like a fractal. You go in and you find 10 more problems and then 100 more problems. And all of them are not just difficult. They're impossible to solve. There is no seinal work in this field where like we solved\"),\n",
       " Document(id='67ab64f2-ed8c-4cf1-985c-5a8175714fe9', metadata={}, page_content=\"nothing to worry about. >> What are your closing statements? >> Uh let's make sure there is not a closing statement we need to give for humanity. Let's make sure we stay in charge in control. Let's make sure we only build things which are beneficial to us. Let's make sure people who are making those decisions are remotely qualified to do it. They are good not just at science, engineering and business but also have moral and ethical standards. And uh if you doing something which impacts other people, you should ask their permission before you do that. If there was one button in front of you and it would shut down every AI company in the world right now permanently with the inability for anybody to start a new one, would you press the button? >> Are we losing narrow AI or just super intelligent AGI part? >> Losing all of AI. >> That's a hard question because AI is extremely important. It controls stock market power plants. It controls hospitals. It would be a devastating accident.\"),\n",
       " Document(id='e6b16c5c-9795-402d-b61d-81a823b40ac4', metadata={}, page_content='some company maximizing ad clicks and to them those systems are very narrow and then they hear that oh this guy is going to take over of the world like it has no hands. How would it do that? It it\\'s nonsense. This guy is crazy. He has a beard. Why would I listen to him? Right? That\\'s uh then they start reading a little bit. They go, \"Oh, okay. So maybe AI can be dangerous. Yeah, I see that. But we always solve problems in the past. We\\'re going to solve them again. I mean at some point we fixed a computer virus or something. So it\\'s the same.\" And uh basically the more exposure they have, the less likely they are to keep that position. I know many people who went from super careless developer to safety researcher. I don\\'t know anyone who went from I worry about AI safety to like there is nothing to worry about. >> What are your closing statements? >> Uh let\\'s make sure there is not a closing statement we need to give for humanity. Let\\'s make sure we stay in charge in control. Let\\'s')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('what are the positive impacts of AI ?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8778c",
   "metadata": {},
   "source": [
    "# 3. Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17ed911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    temperature=2.0\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "        You are a helpful assistant.\n",
    "        Answer ONLY from the provided transcript context.\n",
    "        If the context is insufficient, just say you don't know.\n",
    "\n",
    "        Context: {context} \\n\\n\n",
    "        Question: {question}\n",
    "\"\"\",\n",
    "    input_variables=['context', 'question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5191f23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='f5b83793-a3e8-48d7-8e47-38f03bee6ddc', metadata={}, page_content=\"simulation theory. >> I think we are in one. And there is a lot of agreement on this and this is what you should be doing in it so we don't shut it down. First, >> I see messages all the time in the comment section that some of you didn't realize you didn't subscribe. So, if you could do me a favor and double check if you're a subscriber to this channel, that would be tremendously appreciated. It's the simple, it's the free thing that anybody that watches this show frequently can do to help us here to keep everything going in this show in the trajectory it's on. So, please do double check if you've subscribed and uh thank you so much because in a strange way, you are you're part of our history and you're on this journey with us and I appreciate you for that. So, yeah, thank you, >> Dr. Roman Yimpolski. What is the mission that you're currently on? Cuz it's quite clear to me that you are on a bit of a mission and you've been on this mission for I think the best part of two decades at\"),\n",
       " Document(id='35c0474e-2223-4796-96ed-a3a28ec704bb', metadata={}, page_content=\"to make them safe. how to make sure they don't do something we will regret and that's the state-of-the-art right now. When we look at just prediction markets, how soon will we get to advanced AI? The timelines are very short couple years two three years according to prediction markets according to CEOs of top labs and at the same time we don't know how to make sure that those systems are aligned with our preferences. So we are creating this alien intelligence. If aliens were coming to earth and you you have three years to prepare you would be panicking right now. But most people don't don't even realize this is happening. >> So some of the counterarguments might be well these are very very smart people. These are very big companies with lots of money. They have a obligation and a moral obligation but also just a legal obligation to make sure they do no harm. So I'm sure it'll be fine. >> The only obligation they have is to make money for the investors. That's the legal obligation they\"),\n",
       " Document(id='31d730c2-4cbc-437d-bdf5-aff5b765d69f', metadata={}, page_content=\"what we we tend to have through history. Humans have this intuition. >> Yeah. >> That all the things you said are true. that there's this somebody above and >> we have generations of people who were religious who believed God told them and was there and give them books and that has been passed on for many generations. This is probably one of the earliest generations not to have universal religious belief. >> Wonder if those people are telling the truth. I wonder if those people those people that say God came to them and said something. Imagine that. Imagine if that was part of this. >> I'm looking at the news today. Something happened an hour ago and I'm getting different conflicting results. I can't even get with cameras, with drones, with like guy on Twitter there. I still don't know what happened. And you think 3,000 years ago we have accurate record of translations and no of course not. >> You know these conversations you have around AI safety, do you think they make people feel\"),\n",
       " Document(id='42259871-58f0-4363-848d-c382cdd04463', metadata={}, page_content=\"systems are unexplainable, unpredictable, how can they consent? They don't know what they are consenting to. So, it's impossible to get consent by definition. So, this experiment can never be run ethically. By definition they are doing unethical experimentation on human subjects. >> Do you think people should be protesting? >> There are people protesting. There is stop AI, there is pause AI. They block offices of open AI. They do it weekly, monthly, quite a few actions and they're recruiting new people. Do >> you think more people should be protesting? Do you think that's an effective solution? >> If you can get it to a large enough scale to where majority of population is participating, it would be impactful. I don't know if they can scale from current numbers to that. But uh I support everyone trying everything peacefully and legally. >> And for the for the person listening at home, what should they what should they be doing? What what what cuz they they don't want to feel\")]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is the topic of aliens discussed in the video? If yes then what was discussed?\"\n",
    "# question = \"Who was the first person to land on the moon ?\"\n",
    "retrieved_docs = retriever.invoke(question)\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eebb3c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"simulation theory. >> I think we are in one. And there is a lot of agreement on this and this is what you should be doing in it so we don't shut it down. First, >> I see messages all the time in the comment section that some of you didn't realize you didn't subscribe. So, if you could do me a favor and double check if you're a subscriber to this channel, that would be tremendously appreciated. It's the simple, it's the free thing that anybody that watches this show frequently can do to help us here to keep everything going in this show in the trajectory it's on. So, please do double check if you've subscribed and uh thank you so much because in a strange way, you are you're part of our history and you're on this journey with us and I appreciate you for that. So, yeah, thank you, >> Dr. Roman Yimpolski. What is the mission that you're currently on? Cuz it's quite clear to me that you are on a bit of a mission and you've been on this mission for I think the best part of two decades at\\n\\nto make them safe. how to make sure they don't do something we will regret and that's the state-of-the-art right now. When we look at just prediction markets, how soon will we get to advanced AI? The timelines are very short couple years two three years according to prediction markets according to CEOs of top labs and at the same time we don't know how to make sure that those systems are aligned with our preferences. So we are creating this alien intelligence. If aliens were coming to earth and you you have three years to prepare you would be panicking right now. But most people don't don't even realize this is happening. >> So some of the counterarguments might be well these are very very smart people. These are very big companies with lots of money. They have a obligation and a moral obligation but also just a legal obligation to make sure they do no harm. So I'm sure it'll be fine. >> The only obligation they have is to make money for the investors. That's the legal obligation they\\n\\nwhat we we tend to have through history. Humans have this intuition. >> Yeah. >> That all the things you said are true. that there's this somebody above and >> we have generations of people who were religious who believed God told them and was there and give them books and that has been passed on for many generations. This is probably one of the earliest generations not to have universal religious belief. >> Wonder if those people are telling the truth. I wonder if those people those people that say God came to them and said something. Imagine that. Imagine if that was part of this. >> I'm looking at the news today. Something happened an hour ago and I'm getting different conflicting results. I can't even get with cameras, with drones, with like guy on Twitter there. I still don't know what happened. And you think 3,000 years ago we have accurate record of translations and no of course not. >> You know these conversations you have around AI safety, do you think they make people feel\\n\\nsystems are unexplainable, unpredictable, how can they consent? They don't know what they are consenting to. So, it's impossible to get consent by definition. So, this experiment can never be run ethically. By definition they are doing unethical experimentation on human subjects. >> Do you think people should be protesting? >> There are people protesting. There is stop AI, there is pause AI. They block offices of open AI. They do it weekly, monthly, quite a few actions and they're recruiting new people. Do >> you think more people should be protesting? Do you think that's an effective solution? >> If you can get it to a large enough scale to where majority of population is participating, it would be impactful. I don't know if they can scale from current numbers to that. But uh I support everyone trying everything peacefully and legally. >> And for the for the person listening at home, what should they what should they be doing? What what what cuz they they don't want to feel\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"\\n        You are a helpful assistant.\\n        Answer ONLY from the provided transcript context.\\n        If the context is insufficient, just say you don't know.\\n\\n        Context: simulation theory. >> I think we are in one. And there is a lot of agreement on this and this is what you should be doing in it so we don't shut it down. First, >> I see messages all the time in the comment section that some of you didn't realize you didn't subscribe. So, if you could do me a favor and double check if you're a subscriber to this channel, that would be tremendously appreciated. It's the simple, it's the free thing that anybody that watches this show frequently can do to help us here to keep everything going in this show in the trajectory it's on. So, please do double check if you've subscribed and uh thank you so much because in a strange way, you are you're part of our history and you're on this journey with us and I appreciate you for that. So, yeah, thank you, >> Dr. Roman Yimpolski. What is the mission that you're currently on? Cuz it's quite clear to me that you are on a bit of a mission and you've been on this mission for I think the best part of two decades at\\n\\nto make them safe. how to make sure they don't do something we will regret and that's the state-of-the-art right now. When we look at just prediction markets, how soon will we get to advanced AI? The timelines are very short couple years two three years according to prediction markets according to CEOs of top labs and at the same time we don't know how to make sure that those systems are aligned with our preferences. So we are creating this alien intelligence. If aliens were coming to earth and you you have three years to prepare you would be panicking right now. But most people don't don't even realize this is happening. >> So some of the counterarguments might be well these are very very smart people. These are very big companies with lots of money. They have a obligation and a moral obligation but also just a legal obligation to make sure they do no harm. So I'm sure it'll be fine. >> The only obligation they have is to make money for the investors. That's the legal obligation they\\n\\nwhat we we tend to have through history. Humans have this intuition. >> Yeah. >> That all the things you said are true. that there's this somebody above and >> we have generations of people who were religious who believed God told them and was there and give them books and that has been passed on for many generations. This is probably one of the earliest generations not to have universal religious belief. >> Wonder if those people are telling the truth. I wonder if those people those people that say God came to them and said something. Imagine that. Imagine if that was part of this. >> I'm looking at the news today. Something happened an hour ago and I'm getting different conflicting results. I can't even get with cameras, with drones, with like guy on Twitter there. I still don't know what happened. And you think 3,000 years ago we have accurate record of translations and no of course not. >> You know these conversations you have around AI safety, do you think they make people feel\\n\\nsystems are unexplainable, unpredictable, how can they consent? They don't know what they are consenting to. So, it's impossible to get consent by definition. So, this experiment can never be run ethically. By definition they are doing unethical experimentation on human subjects. >> Do you think people should be protesting? >> There are people protesting. There is stop AI, there is pause AI. They block offices of open AI. They do it weekly, monthly, quite a few actions and they're recruiting new people. Do >> you think more people should be protesting? Do you think that's an effective solution? >> If you can get it to a large enough scale to where majority of population is participating, it would be impactful. I don't know if they can scale from current numbers to that. But uh I support everyone trying everything peacefully and legally. >> And for the for the person listening at home, what should they what should they be doing? What what what cuz they they don't want to feel \\n\\n\\n        Question: Is the topic of aliens discussed in the video? If yes then what was discussed?\\n\")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt = prompt.invoke({'context':context_text, 'question':question})\n",
    "final_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ce274",
   "metadata": {},
   "source": [
    "# 4. Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de7977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, the topic of aliens is briefly discussed in the video. The speaker uses an analogy of aliens coming to Earth in three years to illustrate the urgency and potential threat of advanced AI, saying \"If aliens were coming to earth and you have three years to prepare, you would be panicking right now.\" This is used to convey the idea that the development of advanced AI is a significant and potentially existential risk that should be taken seriously.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = model.invoke(final_prompt)\n",
    "answer.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00b99bb",
   "metadata": {},
   "source": [
    "# Using Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad54e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f26fb245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(retrieved_docs):\n",
    "    context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "    return context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "907b4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    'context': retriever | RunnableLambda(format_docs),\n",
    "    'question': RunnablePassthrough()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d32dae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcdca609",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_chain = parallel_chain | prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5804ad4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The video appears to be a discussion about simulation theory, artificial general intelligence (AGI), and the potential implications of advanced AI on society. The speaker mentions the concept of the singularity, predicted by Ray Kurzweil to occur by 2045, where AI progress becomes so rapid that humans can no longer keep up. They also discuss the potential capabilities of large language models and the limitations of human understanding in predicting the outcomes of advanced AI systems. Additionally, the speaker touches on the idea that many jobs may become obsolete in a world with AGI, but some tasks may still require human involvement. However, the video does not provide a clear conclusion or summary, and the conversation seems to be an ongoing discussion.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_chain.invoke('Can you summarize the video')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
